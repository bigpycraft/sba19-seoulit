# -*- coding: utf-8 -*-
"""190905_과제.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZxB7wJy8w9Nk-e5GWMTtIDm2xThrzxwh
"""

import requests
from bs4 import BeautifulSoup
import re
import pandas as pd

url="https://www.chicagomag.com/Chicago-Magazine/November-2012/Best-Sandwiches-Chicago/"
resp = requests.get(url)

soup=BeautifulSoup(resp.text,"lxml")
rank = soup.find_all('div','sammyRank')
bu_st = soup.find_all('div','sammyListing')
site=bu_st[0].find('a')['href']
type(site)

"""## 가격, 주소, 전화번호, 홈페이지정보"""

Rank =[]
Burger =[]
Store =[]
Site = []
Link=[]
Price=[]
Address=[]
Phone=[]
rank_1=0
link=""

for i,j in enumerate(bu_st):
    tmp = bu_st[i].get_text()
    tmp = tmp.split('\r\n')
    tmp[1] = tmp[1].split('\n')[0]
    rank_1= int(i)+1
    site=bu_st[i].find('a')['href']
    if site.startswith('http://www.chicagomag.com'):
        Site.append(site)
    else:
        site='http://www.chicagomag.com'+site
        Site.append(site)
    
    Rank.append(rank_1)
    Burger.append(tmp[0])
    Store.append(tmp[1])
#     print(site)
    url_1=Site[i]
#     print(url_1)
    resp_1=requests.get(url_1)
    soup_1=BeautifulSoup(resp_1.text,"lxml")
    inner = soup_1.select("p.addy em") #세부사항 데이터 
#     print(inner)
#     print(inner[0].find('a')['href'])
    inner_1=inner[0].get_text()
    if 'http' in str(inner):
        link=inner[0].find('a')['href']
    else:
        link="None"  
    Link.append(link)
    list=inner_1.split('. ') # 스플릿으로 가격을 분리
#     money=list[0].split(' ')
    if '-' in str(inner_1):
        phone=re.findall('[0-9]+-[0-9]+-[0-9]+', inner[0].get_text())
    else:
        phone="None"
#     money_1 = 
    Price.append(list[0])
#     address=re.findall("[0-9]+[A-Za-z.,\s]+",list[1])
#     address=address[0]
#     print(list[1])
#     tmp_4=inner[0].split(". ")
    asd=""
    for c,d in enumerate(list):
      list[c].strip()
      if c>= 1:
        asd += " "+d
  
    address = re.findall("[\w.,\s]+[^\d-]+[^\w.com]+",asd)
    Address.append(address[0])
    Phone.append(phone[0])
#     print(Price)
#     print(Address)
#     print(link)
#     print(url_1)
    print(phone[0])
#     print(list[0])
#     print(address[0])

data = {'Rank':Rank,'Burger':Burger,'Store':Store,"Link":Site,"Price":Price,"Phone":Phone,"Address":Address,"Homepage":Link}

df = pd.DataFrame(data)

df

# df.to_csv("filename_5.csv", mode='a', encoding='KOI8')
df.to_excel("test_1.xlsx")

# Commented out IPython magic to ensure Python compatibility.
# %pwd